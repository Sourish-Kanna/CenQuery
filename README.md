# ğŸ“˜ CenQuery: Specialized Text-to-SQL for Indian Census Data

**CenQuery** is a high-accuracy Natural Language to SQL (NL-to-SQL) system specifically architected for Indian Census datasets. By moving away from generic LLMs, this project utilizes a fine-tuned **Llama-3-SQLCoder-8b** model with **QLoRA adapters** to ensure schema-safe query generation and 100% execution accuracy.

---

## ğŸ—ï¸ System Architecture: The "Soft Reboot"

To solve the "hallucination" problem found in baseline models, CenQuery employs a specialized pipeline:

1. **Base Model:** `defog/llama-3-sqlcoder-8b` (SOTA for SQL generation).
2. **Fine-Tuning:** 4-bit QLoRA (NF4) training on **650+ hand-verified** Indian Census question-SQL pairs.
3. **Deployment:** * **Training:** Google Colab (A100/L4).

* **Inference:** Hugging Face Inference Endpoints (Microservice).
* **Backend:** FastAPI (Python) serving as the bridge.
* **Frontend:** Next.js (TypeScript) for the interactive dashboard.

---

## ğŸ“‚ Project Structure

```text
CenQuery-main/
â”œâ”€â”€ Backend/                # FastAPI Server & Model Clients
â”‚   â”œâ”€â”€ main.py             # API Routes (/api/query)
â”‚   â”œâ”€â”€ model_client.py     # Hugging Face Endpoint integration
â”‚   â””â”€â”€ setup_database.py   # Supabase/PostgreSQL connection logic
â”œâ”€â”€ Dataset/                # The "Golden" Dataset (650 Questions)
â”‚   â”œâ”€â”€ training_data/      # Merged .jsonl files for LoRA training
â”‚   â”œâ”€â”€ data/               # 12 Normalized CSV Tables (Religion, Crop, etc.)
â”‚   â””â”€â”€ database_schema.json# Verified Master Schema
â”œâ”€â”€ Frontend/               # Next.js Application
â”‚   â”œâ”€â”€ src/app/            # Query interface and result visualization
â”‚   â””â”€â”€ public/             # Static assets
â”œâ”€â”€ Training/               # Fine-tuning scripts
â”‚   â””â”€â”€ train_lora.py       # QLoRA training script for Colab
â”œâ”€â”€ Research/               # Academic Documentation
â”‚   â””â”€â”€ Comparative_Analysis.pdf # The Jan 12 Research Paper
â””â”€â”€ README.md

```

---

## ğŸ“Š Dataset & Schema

The model is trained on **12 normalized tables** covering the depth of Indian Census data:

* **Demographics:** `population_stats`, `regions`
* **Social:** `religion_stats`, `language_stats`
* **Economic:** `education_stats`, `occupation_stats`, `healthcare_stats`
* **Agriculture:** `crop_stats`

**Current Status:** âœ… 650 Verified training pairs complete.

---

## ğŸ‘¥ Team & Responsibilities

* **Sourish (Lead):** Model Architecture, QLoRA Fine-tuning, and Backend Integration.
* **Nandhini & Gopikha:** Data Engineering, SQL Verification, and IEEE Documentation.
* **Maharajan:** Frontend Development (Next.js) and UI/UX Deployment.

---

## ğŸš€ Development Workflow

1. **Data Engineering:** Consolidate 650 questions into a schema-aware `.jsonl` format.
2. **Model Training:** Execute QLoRA training on Colab and push adapters to Hugging Face.
3. **Integration:** Connect FastAPI to the HF inference microservice.
4. **Evaluation:** Conduct Comparative Analysis (GPT-3.5 vs. CenQuery) for the research paper.
5. **Review:** Demonstrate end-to-end "Natural Language â†’ SQL â†’ Census Result" on Jan 17.

---

## âš™ï¸ Coding Conventions

* **Model-First:** All SQL must be generated based on the `database_schema.json` to prevent column hallucinations.
* **Clean Code:** Use OOP in the backend; TypeScript for type-safety in the frontend.
* **Documentation:** All project updates must be mirrored in the IEEE Status Report.
